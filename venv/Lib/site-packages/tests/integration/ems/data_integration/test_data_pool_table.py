import pandas as pd
import pytest
from pycelonis.errors import PyCelonisTableAlreadyExistsError, PyCelonisDataPushExecutionFailedError
from pycelonis.pql.pql import PQL, PQLColumn
from pycelonis.service.integration.service import ColumnTransport, ColumnType, PoolColumnType
from tests.unit.conftest import assert_frame_equals


@pytest.mark.vcr()
class TestDataPoolTable:
    def test_data_pool_table(self, pycelonis_data_pool):
        # Test create table
        TABLE_NAME = "TEST_CREATE_TABLE"
        COLUMN_NAME = "TEST_COLUMN"
        df = pd.DataFrame({COLUMN_NAME: [f"TEST_{i}" for i in range(int(10))]})
        data_pool_table = pycelonis_data_pool.create_table(df, TABLE_NAME)
        assert TABLE_NAME in [table.name for table in pycelonis_data_pool.get_tables()]
        assert data_pool_table == pycelonis_data_pool.get_table(TABLE_NAME)

        pool_columns = data_pool_table.get_columns()
        assert len(pool_columns) == 2  # _CELONIS_CHANGE_DATE and `COLUMN_NAME`

        pool_column = [col for col in pool_columns if col.name == COLUMN_NAME][0]
        assert pool_column.length == 80  # Default length

        # Test sync data pool table
        original_source_name = data_pool_table.data_source_name
        data_pool_table.data_source_name = "UPDATED_SOURCE_NAME"
        data_pool_table.sync()
        assert data_pool_table.data_source_name == original_source_name

        # Test create table with same name fails
        with pytest.raises(PyCelonisTableAlreadyExistsError):
            pycelonis_data_pool.create_table(df, TABLE_NAME)

        # Test create table with drop if exists works
        pycelonis_data_pool.create_table(df, TABLE_NAME, drop_if_exists=True, force=True)
        assert TABLE_NAME in [table.name for table in pycelonis_data_pool.get_tables()]

        # Test create table with column_config works
        FIELD_LENGTH = 10
        data_pool_table = pycelonis_data_pool.create_table(
            df,
            TABLE_NAME,
            drop_if_exists=True,
            column_config=[
                ColumnTransport(column_name=COLUMN_NAME, column_type=ColumnType.STRING, field_length=FIELD_LENGTH)
            ],
        )
        assert TABLE_NAME in [table.name for table in pycelonis_data_pool.get_tables()]
        pool_column = [col for col in data_pool_table.get_columns() if col.name == COLUMN_NAME][0]
        assert pool_column.name == COLUMN_NAME
        assert (
            pool_column.length == FIELD_LENGTH * 4
        )  # Field length returned is multiplied by 4 as it's returned in bytes
        assert pool_column.type_ == PoolColumnType.STRING

        # Test append to existing table works
        data_pool_table.append(df)

        # Test upsert to existing table works
        data_pool_table.upsert(df, keys=list(df.columns))

        # Test upsert to existing table with wrong keys throws error
        with pytest.raises(PyCelonisDataPushExecutionFailedError):
            data_pool_table.upsert(df, keys=["NONEXISTENT_KEY"])

    def test_data_pool_table_append_and_upsert(self, pycelonis_data_pool):
        TABLE_NAME = "TEST_APPEND_TABLE"
        df1 = pd.DataFrame({"KEY": [1, 2, 3], "VALUE": [1, 2, 3]})
        df2 = pd.DataFrame({"KEY": [4, 5, 6], "VALUE": [4, 5, 6]})
        df3 = pd.DataFrame({"KEY": [1, 2, 3, 4], "VALUE": [7, 8, 9, 10]})
        final_df = pd.DataFrame({"KEY": [1, 2, 3, 4, 5, 6], "VALUE": [7, 8, 9, 10, 5, 6]})

        query = (
            PQL()
            + PQLColumn(name="KEY", query='"TEST_APPEND_TABLE"."KEY"')
            + PQLColumn(name="VALUE", query='"TEST_APPEND_TABLE"."VALUE"')
        )

        data_pool_table = pycelonis_data_pool.create_table(df1, TABLE_NAME)
        data_model = pycelonis_data_pool.create_data_model("TEST_DATA_MODEL")
        data_model.add_table(TABLE_NAME)
        data_model.reload()
        result_df = data_model.export_data_frame(query)
        assert result_df.shape == (3, 2)

        data_pool_table.append(df2)
        data_model.reload()
        result_df = data_model.export_data_frame(query)
        assert result_df.shape == (6, 2)

        data_pool_table.upsert(df3, keys=["KEY"])
        data_model.reload()
        result_df = data_model.export_data_frame(query)
        assert result_df.shape == (6, 2)
        assert_frame_equals(result_df, final_df)

    def test_data_pool_table_index(self, pycelonis_data_pool):
        df = pd.DataFrame({"TEST": [f"TEST_{i}" for i in range(10)]}, index=[f"TEST_{i}" for i in range(10)])

        # Test create table without index
        data_pool_table = pycelonis_data_pool.create_table(df, "TEST_CREATE_TABLE_NO_INDEX")
        assert len(data_pool_table.get_columns()) == 2

        data_pool_table.upsert(df, keys=["TEST"])
        assert len(data_pool_table.get_columns()) == 2

        data_pool_table.append(df)
        assert len(data_pool_table.get_columns()) == 2

        # Test create table with index
        data_pool_table = pycelonis_data_pool.create_table(df, "TEST_CREATE_TABLE_INDEX", index=True)
        assert len(data_pool_table.get_columns()) == 3

        data_pool_table.upsert(df, keys=["TEST"], index=True)
        assert len(data_pool_table.get_columns()) == 3

        data_pool_table.append(df, index=True)
        assert len(data_pool_table.get_columns()) == 3
