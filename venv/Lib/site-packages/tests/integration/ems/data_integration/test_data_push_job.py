import pandas as pd
import pycelonis.pql as pql
import pytest
from pycelonis.ems import DataModel, DataPool
from pycelonis.pql.pql import PQL, PQLColumn
from pycelonis.service.data_ingestion.service import JobType
from tests.assets import PARQUET_ASSET


@pytest.mark.vcr()
class TestDataPushJob:
    def test_data_push_job(self, pycelonis_data_pool):
        # Test create data push jobs
        data_push_job = pycelonis_data_pool.create_data_push_job("TEST_TABLE_DATA_PUSH", type=JobType.REPLACE)

        # Test data push job exists within data pool
        assert pycelonis_data_pool.get_data_push_job(data_push_job.id) == data_push_job

        # Test data push job exists within data pool
        assert pycelonis_data_pool.get_data_push_job(data_push_job.id) == data_push_job
        assert data_push_job.id in [j.id for j in pycelonis_data_pool.get_data_push_jobs()]

        # Test sync data push job
        original_name = data_push_job.target_name
        data_push_job.target_name = data_push_job.target_name + "_UPDATED"
        data_push_job.sync()
        assert data_push_job.target_name == original_name

        # Test add data frame
        df = pd.DataFrame({"TEST_COLUMN": list(range(int(10)))})
        data_push_job.add_data_frame(df, chunk_size=5)
        assert len(data_push_job.get_chunks()) == 2

        # Test add file chunk
        with open(PARQUET_ASSET, "rb") as f:
            data_push_job.add_file_chunk(f)
        assert len(data_push_job.get_chunks()) == 3

    def test_data_delete_job(self, pycelonis_data_pool):
        # Add data frame
        data_push_job = pycelonis_data_pool.create_data_push_job("TEST_TABLE_DATA_PUSH", type=JobType.REPLACE)
        df = pd.DataFrame({"TEST_COLUMN": list(range(int(10)))})
        data_push_job.add_data_frame(df, chunk_size=5)
        assert len(data_push_job.get_chunks()) == 2
        data_push_job.execute(wait=True)

        # Create data model
        dm = pycelonis_data_pool.create_data_model("TEST_DATA_MODEL")
        dm.add_table("TEST_TABLE_DATA_PUSH", alias="TEST_TABLE_DATA_PUSH")
        dm.reload()

        # Create PQL query
        query = PQL()
        query += PQLColumn(name="TEST_COLUMN", query=""" "TEST_TABLE_DATA_PUSH"."TEST_COLUMN" """)

        # Validate insertion
        result_df = dm.export_data_frame(query)
        assert len(result_df) == 10

        # Test delete data frame
        data_delete_job = pycelonis_data_pool.create_data_push_job(
            "TEST_TABLE_DATA_PUSH", type=JobType.DELTA, keys=["TEST_COLUMN"]
        )
        delete_df = df.loc[[0, 1, 2]]
        data_delete_job.delete_data_frame(delete_df)
        data_delete_job.execute(wait=True)

        # Reload dm
        dm.reload()

        # Validate deletion
        result_df = dm.export_data_frame(query)
        assert len(result_df) == 7
        for i in range(3):
            assert i not in result_df.values

        for i in range(4, 10):
            assert i in result_df.values

    def test_dtypes_are_properly_chunked(self, pycelonis_data_pool: DataPool, pycelonis_data_model: DataModel):
        df = pd.DataFrame(
            {
                "TEST_INTEGER": [1, 2],
                "TEST_DATETIME": pd.to_datetime(["2021-01-01 00:00:00", "2021-01-02 00:00:00"]),
                "TEST_FLOAT": [1.0, 2.0],
                "TEST_BOOLEAN": [True, False],
                "TEST_STRING": ["1", "2"],
                "ID": range(2),
            }
        )
        initial_dtypes = df.dtypes

        table = pycelonis_data_pool.create_table(df, "TEST_TABLE")
        assert df.dtypes.equals(initial_dtypes)

        upsert_df = pd.DataFrame(
            {
                "TEST_INTEGER": [None, 1],
                "TEST_DATETIME": [None, pd.to_datetime("2021-01-01 00:00:00")],
                "TEST_FLOAT": [None, 1.0],
                "TEST_BOOLEAN": [None, True],
                "TEST_STRING": [None, "TEST"],
                "ID": range(2),
            }
        )
        table.upsert(upsert_df, keys=["ID"], chunk_size=1)
        assert len(table.get_columns()) == 7

        pycelonis_data_model.add_table(name="TEST_TABLE", alias="TEST_TABLE")
        pycelonis_data_model.reload()

        table = pycelonis_data_model.get_tables().find("TEST_TABLE")
        cols = table.get_columns()
        df_pql = pql.DataFrame(
            {
                "TEST_INTEGER": cols.find("TEST_INTEGER"),
                "TEST_DATETIME": cols.find("TEST_DATETIME"),
                "TEST_FLOAT": cols.find("TEST_FLOAT"),
                "TEST_BOOLEAN": cols.find("TEST_BOOLEAN"),
                "TEST_STRING": cols.find("TEST_STRING"),
                "ID": cols.find("ID"),
            },
            data_model=pycelonis_data_model,
        )
        df_pql = df_pql.to_pandas()

        df_pql = df_pql.sort_values("ID")  # prevent confusion from ID 1 coming below
        upsert_df.index = df_pql.index

        pd.testing.assert_frame_equal(df_pql, upsert_df, check_names=False, check_index_type=False, check_dtype=False)
