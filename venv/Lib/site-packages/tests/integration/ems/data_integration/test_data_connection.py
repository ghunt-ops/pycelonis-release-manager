import pandas as pd
import pytest
from pycelonis.service.data_ingestion.service import JobType
from pycelonis_core.utils.errors import PyCelonisNotFoundError


@pytest.mark.vcr()
class TestDataConnection:
    def test_data_connection(self, big_query_data_connection, pycelonis_data_pool):
        # Test data connection exists within data pool
        assert pycelonis_data_pool.get_data_connection(big_query_data_connection.id).id == big_query_data_connection.id
        assert big_query_data_connection.id in [j.id for j in pycelonis_data_pool.get_data_connections()]

        # Test sync data connection
        original_name = big_query_data_connection.name
        big_query_data_connection.name = big_query_data_connection.name + "_UPDATED"
        big_query_data_connection.sync()
        assert big_query_data_connection.name == original_name

        # Test get tables for data connection
        assert len(big_query_data_connection.get_tables()) >= 1

        taxi_trips_table = big_query_data_connection.get_tables("taxi_trips")
        assert len(taxi_trips_table) == 1
        assert taxi_trips_table[0].name == "taxi_trips"
        assert taxi_trips_table[0].schema_ == "bq-project-main.dataset_public_1"

        nonexistent_table = big_query_data_connection.get_tables("NONEXISTENT_TABLE")
        assert len(nonexistent_table) == 0

        # Test create table within data connection
        df = pd.DataFrame({"TEST_COLUMN": [1, 2]})
        table = pycelonis_data_pool.create_table(df, "TEST_TABLE", data_source_id=big_query_data_connection.id)

        synced_table = pycelonis_data_pool.get_table("TEST_TABLE", data_source_id=big_query_data_connection.id)
        assert table.name == synced_table.name
        assert table.data_source_id == synced_table.data_source_id
        assert table.name in [t.name for t in pycelonis_data_pool.get_tables()]

        columns = table.get_columns()
        assert len(columns) == 2  # _CELONIS_CHANGE_DATE and TEST_COLUMN
        assert columns.find("TEST_COLUMN").name == "TEST_COLUMN"

        # Test upsert table within data connection
        table.upsert(df, keys=["TEST_COLUMN"])

        # Test append table within data connection
        table.append(df)

        # Test create data push pycelonis_job within data connection
        data_push_job = pycelonis_data_pool.create_data_push_job(
            target_name="TEST_TABLE_2",
            type_=JobType.REPLACE,
            connection_id=big_query_data_connection.id,
        )
        data_push_job.add_data_frame(df)
        data_push_job.execute(wait=True)

        synced_table = pycelonis_data_pool.get_table("TEST_TABLE_2", data_source_id=big_query_data_connection.id)
        assert "TEST_TABLE_2" == synced_table.name
        assert synced_table.data_source_id == big_query_data_connection.id
        assert "TEST_TABLE_2" in [t.name for t in pycelonis_data_pool.get_tables()]

        # Test create pycelonis_job within data connection
        job = pycelonis_data_pool.create_job("TEST_JOB", data_source_id=big_query_data_connection.id)

        assert job.id == pycelonis_data_pool.get_job(job.id).id
        assert job.id in [j.id for j in pycelonis_data_pool.get_jobs()]

        # Test delete data connection
        big_query_data_connection.delete()
        assert big_query_data_connection.id not in [j.id for j in pycelonis_data_pool.get_data_connections()]
        with pytest.raises(PyCelonisNotFoundError):
            pycelonis_data_pool.get_data_connection(big_query_data_connection.id)

        # Test data connection representation
        representation = repr(big_query_data_connection)
        for attribute in big_query_data_connection.__main_attributes__():
            assert attribute in representation
